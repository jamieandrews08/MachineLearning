{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load helper.py\n",
    "\"\"\"\n",
    "Created on Fri Jan 20 13:55:38 2017\n",
    "@author: JTay\n",
    "source = https://github.com/JonathanTay/CS-7641-assignment-1\n",
    "\n",
    "Adapted by Jamie Andrews\n",
    "CS7461 Assignment 1\n",
    "Feb 3, 2019\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from time import clock\n",
    "import sklearn.model_selection as ms\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn.tree import DecisionTreeClassifier as dtclf\n",
    "\n",
    "\n",
    "def balanced_accuracy(truth,pred):\n",
    "    wts = compute_sample_weight('balanced',truth)\n",
    "    return accuracy_score(truth,pred,sample_weight=wts)\n",
    "\n",
    "scorer = make_scorer(balanced_accuracy)    \n",
    "    \n",
    "def basicResults(clfObj,trgX,trgY,tstX,tstY,params,clf_type=None,dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    cv = ms.GridSearchCV(clfObj,n_jobs=1,param_grid=params,refit=True,verbose=10,cv=5,scoring=scorer)\n",
    "    cv.fit(trgX,trgY)\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    regTable.to_csv('./output/{}_{}_reg.csv'.format(clf_type,dataset),index=False)\n",
    "    test_score = cv.score(tstX,tstY)\n",
    "    with open('./output/test results.csv','a') as f:\n",
    "        f.write('{},{},{},{}\\n'.format(clf_type,dataset,test_score,cv.best_params_))    \n",
    "    N = trgY.shape[0]    \n",
    "    curve = ms.learning_curve(cv.best_estimator_,trgX,trgY,cv=5,\n",
    "                              train_sizes=[50,100]+[int(N*x/10) for x in range(1,7)],verbose=10,scoring=scorer)\n",
    "    curve_train_scores = pd.DataFrame(index = curve[0],data = curve[1])\n",
    "    curve_test_scores  = pd.DataFrame(index = curve[0],data = curve[2])\n",
    "    curve_train_scores.to_csv('./output/{}_{}_LC_train.csv'.format(clf_type,dataset))\n",
    "    curve_test_scores.to_csv('./output/{}_{}_LC_test.csv'.format(clf_type,dataset))\n",
    "    return cv\n",
    "\n",
    "    \n",
    "def iterationLC(clfObj,trgX,trgY,tstX,tstY,params,clf_type=None,dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    cv = ms.GridSearchCV(clfObj,n_jobs=1,param_grid=params,refit=True,verbose=10,cv=5,scoring=scorer)\n",
    "    cv.fit(trgX,trgY)\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    regTable.to_csv('./output/ITER_base_{}_{}.csv'.format(clf_type,dataset),index=False)\n",
    "    d = defaultdict(list)\n",
    "    name = list(params.keys())[0]\n",
    "    for value in list(params.values())[0]:        \n",
    "        d['param_{}'.format(name)].append(value)\n",
    "        clfObj.set_params(**{name:value})\n",
    "        clfObj.fit(trgX,trgY)\n",
    "        pred = clfObj.predict(trgX)\n",
    "        d['train acc'].append(balanced_accuracy(trgY,pred))\n",
    "        clfObj.fit(trgX,trgY)\n",
    "        pred = clfObj.predict(tstX)\n",
    "        d['test acc'].append(balanced_accuracy(tstY,pred))\n",
    "        print(value)\n",
    "    d = pd.DataFrame(d)\n",
    "    d.to_csv('./output/ITERtestSET_{}_{}.csv'.format(clf_type,dataset),index=False)\n",
    "    return cv    \n",
    "    \n",
    "def add_noise(y,frac=0.1):\n",
    "    np.random.seed(456)\n",
    "    n = y.shape[0]\n",
    "    sz = int(n*frac)\n",
    "    ind = np.random.choice(np.arange(n),size=sz,replace=False)\n",
    "    tmp = y.copy()\n",
    "    tmp[ind] = 1-tmp[ind]\n",
    "    return tmp\n",
    "    \n",
    "    \n",
    "def makeTimingCurve(X,Y,clf,clfName,dataset):\n",
    "    out = defaultdict(dict)\n",
    "    for frac in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:    \n",
    "        X_train, X_test, y_train, y_test = ms.train_test_split(X, Y, test_size=frac, random_state=42)\n",
    "        st = clock()\n",
    "        np.random.seed(55)\n",
    "        clf.fit(X_train,y_train)\n",
    "        out['train'][frac]= clock()-st\n",
    "        st = clock()\n",
    "        clf.predict(X_test)\n",
    "        out['test'][frac]= clock()-st\n",
    "        print(clfName,dataset,frac)\n",
    "    out = pd.DataFrame(out)\n",
    "    out.to_csv('./output/{}_{}_timing.csv'.format(clfName,dataset))\n",
    "    return \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "class dtclf_pruned(dtclf):        \n",
    "    def remove_subtree(self,root):\n",
    "        '''Clean up'''\n",
    "        tree = self.tree_\n",
    "        visited,stack= set(),[root]\n",
    "        while stack:\n",
    "            v = stack.pop()\n",
    "            visited.add(v)\n",
    "            left =tree.children_left[v]\n",
    "            right=tree.children_right[v]\n",
    "            if left >=0:\n",
    "                stack.append(left)\n",
    "            if right >=0:\n",
    "                stack.append(right)\n",
    "        for node in visited:\n",
    "            tree.children_left[node] = -1\n",
    "            tree.children_right[node] = -1\n",
    "        return \n",
    "        \n",
    "    def prune(self):      \n",
    "        C = 1-self.alpha\n",
    "        if self.alpha <= -1: # Early exit\n",
    "            return self\n",
    "        tree = self.tree_        \n",
    "        bestScore = self.score(self.valX,self.valY)        \n",
    "        candidates = np.flatnonzero(tree.children_left>=0)\n",
    "        for candidate in reversed(candidates): # Go backwards/leaves up\n",
    "            if tree.children_left[candidate]==tree.children_right[candidate]: # leaf node. Ignore\n",
    "                continue\n",
    "            left = tree.children_left[candidate]\n",
    "            right = tree.children_right[candidate]\n",
    "            tree.children_left[candidate]=tree.children_right[candidate]=-1            \n",
    "            score = self.score(self.valX,self.valY)\n",
    "            if score >= C*bestScore:\n",
    "                bestScore = score                \n",
    "                self.remove_subtree(candidate)\n",
    "            else:\n",
    "                tree.children_left[candidate]=left\n",
    "                tree.children_right[candidate]=right\n",
    "        assert (self.tree_.children_left>=0).sum() == (self.tree_.children_right>=0).sum() \n",
    "        return self\n",
    "        \n",
    "    def fit(self,X,Y,sample_weight=None,check_input=True, X_idx_sorted=None):        \n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones(X.shape[0]) \n",
    "        self.trgX = X.copy()\n",
    "        self.trgY = Y.copy()\n",
    "        self.trgWts = sample_weight.copy()        \n",
    "        sss = ms.StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=123)\n",
    "        for train_index, test_index in sss.split(self.trgX,self.trgY):\n",
    "            self.valX = self.trgX[test_index]\n",
    "            self.valY = self.trgY[test_index]\n",
    "            self.trgX = self.trgX[train_index]\n",
    "            self.trgY = self.trgY[train_index]\n",
    "            self.valWts = sample_weight[test_index]\n",
    "            self.trgWts = sample_weight[train_index]\n",
    "        super().fit(self.trgX,self.trgY,self.trgWts,check_input,X_idx_sorted)\n",
    "        self.prune()\n",
    "        return self\n",
    "    def __init__(self,\n",
    "                 criterion=\"gini\",\n",
    "                 splitter=\"best\",\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.,\n",
    "                 max_features=None,\n",
    "                 random_state=None,\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_split=1e-7,\n",
    "                 class_weight=None,\n",
    "                 presort=False,\n",
    "                 alpha = 0):\n",
    "        super(dtclf_pruned, self).__init__(\n",
    "            criterion=criterion,\n",
    "            splitter=splitter,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_features=max_features,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            class_weight=class_weight,\n",
    "            random_state=random_state,\n",
    "            min_impurity_split=min_impurity_split,\n",
    "            presort=presort)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def numNodes(self):\n",
    "        assert (self.tree_.children_left>=0).sum() == (self.tree_.children_right>=0).sum() \n",
    "        return  (self.tree_.children_left>=0).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Created on Fri Jan 20 15:42:58 2017\n",
    "@author: JTay\n",
    "source = https://github.com/JonathanTay/CS-7641-assignment-1\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.neighbors import KNeighborsClassifier as knnC\n",
    "import pandas as pd\n",
    "#from helpers import  basicResults,makeTimingCurve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # GET THE DATA\n",
    "# wine data\n",
    "file_path =\"./data/\"\n",
    "wine = pd.read_csv (file_path+'wines.csv', sep =\",\")\n",
    "# credit data\n",
    "file_path2 =\"./data/\"\n",
    "credit = pd.read_csv (file_path2+'credit.csv', sep =\",\")\n",
    "\n",
    "#credit = pd.read_hdf('datasets.hdf','credit')        \n",
    "creditX = credit.drop('default',1).copy().values\n",
    "creditY = credit['default'].copy().values\n",
    "\n",
    "#wine = pd.read_hdf('datasets.hdf','wine')        \n",
    "wineX = wine.drop('quality',1).copy().values\n",
    "wineY = wine['quality'].copy().values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into test and training sets\n",
    "credit_trgX, credit_tstX, credit_trgY, credit_tstY = ms.train_test_split(creditX, creditY, test_size=0.3, random_state=0,stratify=creditY)     \n",
    "wine_trgX, wine_tstX, wine_trgY, wine_tstY = ms.train_test_split(wineX, wineY, test_size=0.3, random_state=0,stratify=wineY)     \n",
    "\n",
    "# define alphas and pipeline\n",
    "dc = creditX.shape[1]\n",
    "hiddens_credit = [(h,)*l for l in [1,2,3] for h in [dc,dc//2,dc*2]]\n",
    "alphas = [10**-x for x in np.arange(1,9.01,1/2)]\n",
    "dw = wineX.shape[1]\n",
    "hiddens_wine = [(h,)*l for l in [1,2,3] for h in [dw,dw//2,dw*2]]\n",
    "\n",
    "\n",
    "pipeM = Pipeline([('Scale',StandardScaler()),\n",
    "                  # no need for feature selection\n",
    "#                  ('Cull1',SelectFromModel(RandomForestClassifier(),threshold='median')),\n",
    "#                  ('Cull2',SelectFromModel(RandomForestClassifier(),threshold='median')),\n",
    "#                  ('Cull3',SelectFromModel(RandomForestClassifier(),threshold='median')),\n",
    "#                  ('Cull4',SelectFromModel(RandomForestClassifier(),threshold='median')),\n",
    "                 ('KNN',knnC())])  \n",
    "\n",
    "pipeA = Pipeline([('Scale',StandardScaler()),                \n",
    "                 ('KNN',knnC())])  \n",
    "\n",
    "\n",
    "# define different parameters to try\n",
    "# wine has ~6,000 obs, we expect best k somewhere around 77\n",
    "params_wine= {'KNN__metric':['manhattan','euclidean'],'KNN__n_neighbors':np.arange(7,149,7),'KNN__weights':['uniform','distance']}\n",
    "# credit has 30,000 observations; sqrt(30,000)= 173 so we expect best k near 173\n",
    "params_credit= {'KNN__metric':['manhattan','euclidean'],'KNN__n_neighbors':np.arange(41,251,20),'KNN__weights':['uniform','distance']}\n",
    "\n",
    "\n",
    "# run to determine best parameters, ignore deprecation warnings\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    #import md5, sha\n",
    "\n",
    "\n",
    "    # get results of each parameter set\n",
    "    wine_clf = basicResults(pipeM,wine_trgX,wine_trgY,wine_tstX,wine_tstY,params_wine,'KNN','wine')        \n",
    "    credit_clf = basicResults(pipeA,credit_trgX,credit_trgY,credit_tstX,credit_tstY,params_credit,'KNN','credit')        \n",
    "\n",
    "\n",
    "#wine_final_params={'KNN__n_neighbors': 43, 'KNN__weights': 'uniform', 'KNN__p': 1}\n",
    "#credit_final_params={'KNN__n_neighbors': 142, 'KNN__p': 1, 'KNN__weights': 'uniform'}\n",
    "wine_final_params=wine_clf.best_params_\n",
    "credit_final_params=credit_clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it \n",
    "pipeM.set_params(**wine_final_params)\n",
    "makeTimingCurve(wineX,wineY,pipeM,'KNN','wine')\n",
    "pipeA.set_params(**credit_final_params)\n",
    "makeTimingCurve(creditX,creditY,pipeA,'KNN','credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
