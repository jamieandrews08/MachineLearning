{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bring in python file\n",
    "# %load helper.py\n",
    "\n",
    "\"\"\"\n",
    "Originally Created on Fri Jan 20 13:55:38 2017\n",
    "@author: JTay\n",
    "source = https://github.com/JonathanTay/CS-7641-assignment-1\n",
    "\n",
    "Altered by Jamie Andrews\n",
    "February 2019\n",
    "CS7461 Assignment 1\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from time import clock\n",
    "import sklearn.model_selection as ms\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn.tree import DecisionTreeClassifier as dtclf\n",
    "\n",
    "\n",
    "def balanced_accuracy(truth,pred):\n",
    "    wts = compute_sample_weight('balanced',truth)\n",
    "    return accuracy_score(truth,pred,sample_weight=wts)\n",
    "\n",
    "scorer = make_scorer(balanced_accuracy)    \n",
    "    \n",
    "def basicResults_wine(clfObj,trgX,trgY,tstX,tstY,params,clf_type=None,dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    # cv set to 3 for wine data to insure n is suffciently large with each cross cut\n",
    "    cv = ms.GridSearchCV(clfObj,n_jobs=1,param_grid=params,refit=True,verbose=10,cv=3,scoring=scorer)\n",
    "    cv.fit(trgX,trgY)\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    regTable.to_csv('./output/{}_{}_reg.csv'.format(clf_type,dataset),index=False)\n",
    "    test_score = cv.score(tstX,tstY)\n",
    "    with open('./output/test results.csv','a') as f:\n",
    "        f.write('{},{},{},{}\\n'.format(clf_type,dataset,test_score,cv.best_params_))    \n",
    "    N = trgY.shape[0]    \n",
    "    curve = ms.learning_curve(cv.best_estimator_,trgX,trgY,cv=3,\n",
    "                              train_sizes=[100,250]+[int(N*x/10) for x in range(1,7)],verbose=10,scoring=scorer)\n",
    "    curve_train_scores = pd.DataFrame(index = curve[0],data = curve[1])\n",
    "    curve_test_scores  = pd.DataFrame(index = curve[0],data = curve[2])\n",
    "    curve_train_scores.to_csv('./output/{}_{}_LC_train.csv'.format(clf_type,dataset))\n",
    "    curve_test_scores.to_csv('./output/{}_{}_LC_test.csv'.format(clf_type,dataset))\n",
    "    return cv\n",
    "\n",
    "def basicResults_credit(clfObj,trgX,trgY,tstX,tstY,params,clf_type=None,dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    # cv =5 for credit data bc there is more data to sample from\n",
    "    cv = ms.GridSearchCV(clfObj,n_jobs=1,param_grid=params,refit=True,verbose=10,cv=5,scoring=scorer)\n",
    "    cv.fit(trgX,trgY)\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    regTable.to_csv('./output/{}_{}_reg.csv'.format(clf_type,dataset),index=False)\n",
    "    test_score = cv.score(tstX,tstY)\n",
    "    with open('./output/test results.csv','a') as f:\n",
    "        f.write('{},{},{},{}\\n'.format(clf_type,dataset,test_score,cv.best_params_))    \n",
    "    N = trgY.shape[0]    \n",
    "    curve = ms.learning_curve(cv.best_estimator_,trgX,trgY,cv=5,\n",
    "                              train_sizes=[250,500,1000]+[int(N*x/10) for x in range(1,7)],verbose=10,scoring=scorer)\n",
    "    curve_train_scores = pd.DataFrame(index = curve[0],data = curve[1])\n",
    "    curve_test_scores  = pd.DataFrame(index = curve[0],data = curve[2])\n",
    "    curve_train_scores.to_csv('./output/{}_{}_LC_train.csv'.format(clf_type,dataset))\n",
    "    curve_test_scores.to_csv('./output/{}_{}_LC_test.csv'.format(clf_type,dataset))\n",
    "    return cv\n",
    "    \n",
    "def iterationLC_wine(clfObj,trgX,trgY,tstX,tstY,params,clf_type=None,dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    cv = ms.GridSearchCV(clfObj,n_jobs=1,param_grid=params,refit=True,verbose=10,cv=3,scoring=scorer)\n",
    "    cv.fit(trgX,trgY)\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    regTable.to_csv('./output/ITER_base_{}_{}.csv'.format(clf_type,dataset),index=False)\n",
    "    d = defaultdict(list)\n",
    "    name = list(params.keys())[0]\n",
    "    for value in list(params.values())[0]:        \n",
    "        d['param_{}'.format(name)].append(value)\n",
    "        clfObj.set_params(**{name:value})\n",
    "        clfObj.fit(trgX,trgY)\n",
    "        pred = clfObj.predict(trgX)\n",
    "        d['train acc'].append(balanced_accuracy(trgY,pred))\n",
    "        clfObj.fit(trgX,trgY)\n",
    "        pred = clfObj.predict(tstX)\n",
    "        d['test acc'].append(balanced_accuracy(tstY,pred))\n",
    "        print(value)\n",
    "    d = pd.DataFrame(d)\n",
    "    d.to_csv('./output/ITERtestSET_{}_{}.csv'.format(clf_type,dataset),index=False)\n",
    "    return cv    \n",
    "\n",
    "def iterationLC_credit(clfObj,trgX,trgY,tstX,tstY,params,clf_type=None,dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    cv = ms.GridSearchCV(clfObj,n_jobs=1,param_grid=params,refit=True,verbose=10,cv=5,scoring=scorer)\n",
    "    cv.fit(trgX,trgY)\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    regTable.to_csv('./output/ITER_base_{}_{}.csv'.format(clf_type,dataset),index=False)\n",
    "    d = defaultdict(list)\n",
    "    name = list(params.keys())[0]\n",
    "    for value in list(params.values())[0]:        \n",
    "        d['param_{}'.format(name)].append(value)\n",
    "        clfObj.set_params(**{name:value})\n",
    "        clfObj.fit(trgX,trgY)\n",
    "        pred = clfObj.predict(trgX)\n",
    "        d['train acc'].append(balanced_accuracy(trgY,pred))\n",
    "        clfObj.fit(trgX,trgY)\n",
    "        pred = clfObj.predict(tstX)\n",
    "        d['test acc'].append(balanced_accuracy(tstY,pred))\n",
    "        print(value)\n",
    "    d = pd.DataFrame(d)\n",
    "    d.to_csv('./output/ITERtestSET_{}_{}.csv'.format(clf_type,dataset),index=False)\n",
    "    return cv    \n",
    "    \n",
    "def add_noise(y,frac=0.1):\n",
    "    np.random.seed(456)\n",
    "    n = y.shape[0]\n",
    "    sz = int(n*frac)\n",
    "    ind = np.random.choice(np.arange(n),size=sz,replace=False)\n",
    "    tmp = y.copy()\n",
    "    tmp[ind] = 1-tmp[ind]\n",
    "    return tmp\n",
    "    \n",
    "    \n",
    "def makeTimingCurve(X,Y,clf,clfName,dataset):\n",
    "    out = defaultdict(dict)\n",
    "    for frac in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:    \n",
    "        X_train, X_test, y_train, y_test = ms.train_test_split(X, Y, test_size=frac, random_state=42)\n",
    "        st = clock()\n",
    "        np.random.seed(55)\n",
    "        clf.fit(X_train,y_train)\n",
    "        out['train'][frac]= clock()-st\n",
    "        st = clock()\n",
    "        clf.predict(X_test)\n",
    "        out['test'][frac]= clock()-st\n",
    "        print(clfName,dataset,frac)\n",
    "    out = pd.DataFrame(out)\n",
    "    out.to_csv('./output/{}_{}_timing.csv'.format(clfName,dataset))\n",
    "    return \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "class dtclf_pruned(dtclf):        \n",
    "    def remove_subtree(self,root):\n",
    "        '''Clean up'''\n",
    "        tree = self.tree_\n",
    "        visited,stack= set(),[root]\n",
    "        while stack:\n",
    "            v = stack.pop()\n",
    "            visited.add(v)\n",
    "            left =tree.children_left[v]\n",
    "            right=tree.children_right[v]\n",
    "            if left >=0:\n",
    "                stack.append(left)\n",
    "            if right >=0:\n",
    "                stack.append(right)\n",
    "        for node in visited:\n",
    "            tree.children_left[node] = -1\n",
    "            tree.children_right[node] = -1\n",
    "        return \n",
    "        \n",
    "    def prune(self):      \n",
    "        C = 1-self.alpha\n",
    "        if self.alpha <= -1: # Early exit\n",
    "            return self\n",
    "        tree = self.tree_        \n",
    "        bestScore = self.score(self.valX,self.valY)        \n",
    "        candidates = np.flatnonzero(tree.children_left>=0)\n",
    "        for candidate in reversed(candidates): # Go backwards/leaves up\n",
    "            if tree.children_left[candidate]==tree.children_right[candidate]: # leaf node. Ignore\n",
    "                continue\n",
    "            left = tree.children_left[candidate]\n",
    "            right = tree.children_right[candidate]\n",
    "            tree.children_left[candidate]=tree.children_right[candidate]=-1            \n",
    "            score = self.score(self.valX,self.valY)\n",
    "            if score >= C*bestScore:\n",
    "                bestScore = score                \n",
    "                self.remove_subtree(candidate)\n",
    "            else:\n",
    "                tree.children_left[candidate]=left\n",
    "                tree.children_right[candidate]=right\n",
    "        assert (self.tree_.children_left>=0).sum() == (self.tree_.children_right>=0).sum() \n",
    "        return self\n",
    "        \n",
    "    def fit(self,X,Y,sample_weight=None,check_input=True, X_idx_sorted=None):        \n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones(X.shape[0]) \n",
    "        self.trgX = X.copy()\n",
    "        self.trgY = Y.copy()\n",
    "        self.trgWts = sample_weight.copy()        \n",
    "        sss = ms.StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=123)\n",
    "        for train_index, test_index in sss.split(self.trgX,self.trgY):\n",
    "            self.valX = self.trgX[test_index]\n",
    "            self.valY = self.trgY[test_index]\n",
    "            self.trgX = self.trgX[train_index]\n",
    "            self.trgY = self.trgY[train_index]\n",
    "            self.valWts = sample_weight[test_index]\n",
    "            self.trgWts = sample_weight[train_index]\n",
    "        super().fit(self.trgX,self.trgY,self.trgWts,check_input,X_idx_sorted)\n",
    "        self.prune()\n",
    "        return self\n",
    "    def __init__(self,\n",
    "                 criterion=\"gini\",\n",
    "                 splitter=\"best\",\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.,\n",
    "                 max_features=None,\n",
    "                 random_state=None,\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_split=1e-7,\n",
    "                 class_weight=None,\n",
    "                 presort=False,\n",
    "                 alpha = 0):\n",
    "        super(dtclf_pruned, self).__init__(\n",
    "            criterion=criterion,\n",
    "            splitter=splitter,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_features=max_features,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            class_weight=class_weight,\n",
    "            random_state=random_state,\n",
    "            min_impurity_split=min_impurity_split,\n",
    "            presort=presort)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def numNodes(self):\n",
    "        assert (self.tree_.children_left>=0).sum() == (self.tree_.children_right>=0).sum() \n",
    "        return  (self.tree_.children_left>=0).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Originally Created on Fri Jan 20 2017\n",
    "@author: JTay\n",
    "source = https://github.com/JonathanTay/CS-7641-assignment-1\n",
    "\n",
    "Altered by Jamie Andrews\n",
    "February 2019\n",
    "CS7461 Assignment 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "import pandas as pd\n",
    "from helpers import  basicResults,makeTimingCurve,iterationLC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class primalSVM_RBF(BaseEstimator, ClassifierMixin):\n",
    "    '''http://scikit-learn.org/stable/developers/contributing.html'''\n",
    "    \n",
    "    def __init__(self, alpha=1e-9,gamma_frac=0.1,max_iter=2000):\n",
    "        self.alpha = alpha\n",
    "        self.gamma_frac = gamma_frac\n",
    "        self.max_iter = max_iter\n",
    "         \n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "         \n",
    "        # Get the kernel matrix\n",
    "        dist = euclidean_distances(X,squared=True)\n",
    "        median = np.median(dist) \n",
    "        del dist\n",
    "        gamma = median\n",
    "        gamma *= self.gamma_frac\n",
    "        self.gamma = 1/gamma\n",
    "        kernels = rbf_kernel(X,None,self.gamma )\n",
    "         \n",
    "        self.X_ = X\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.kernels_ = kernels\n",
    "        self.y_ = y\n",
    "        self.clf = SGDClassifier(loss='hinge',penalty='l2',alpha=self.alpha,\n",
    "                                  l1_ratio=0,fit_intercept=True,verbose=False,\n",
    "                                  average=False,learning_rate='optimal',\n",
    "                                  class_weight='balanced',max_iter=self.max_iter,\n",
    "                                  random_state=55)         \n",
    "        self.clf.fit(self.kernels_,self.y_)\n",
    "         \n",
    "         # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['X_', 'y_','clf','kernels_'])\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        new_kernels = rbf_kernel(X,self.X_,self.gamma )\n",
    "        pred = self.clf.predict(new_kernels)\n",
    "        return pred\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # GET THE DATA\n",
    "# wine data\n",
    "file_path =\"./data/\"\n",
    "wine = pd.read_csv (file_path+'wines.csv', sep =\",\")\n",
    "# credit data\n",
    "file_path2 =\"./data/\"\n",
    "credit = pd.read_csv (file_path2+'credit.csv', sep =\",\")\n",
    "\n",
    "# limit credit data set to 10,000 observations so select rows at random\n",
    "credit = credit.sample(n=9999)\n",
    "len(credit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DIVIDE INTO TRAIN AND TEST SETS\n",
    "\n",
    "#credit = pd.read_hdf('datasets.hdf','credit')        \n",
    "creditX = credit.drop('default',1).copy().values\n",
    "creditY = credit['default'].copy().values\n",
    "\n",
    "#wine = pd.read_hdf('datasets.hdf','wine')        \n",
    "wineX = wine.drop('quality',1).copy().values\n",
    "wineY = wine['quality'].copy().values\n",
    "\n",
    "credit_trgX, credit_tstX, credit_trgY, credit_tstY = ms.train_test_split(creditX, creditY, test_size=0.3, random_state=0,stratify=creditY)     \n",
    "wine_trgX, wine_tstX, wine_trgY, wine_tstY = ms.train_test_split(wineX, wineY, test_size=0.3, random_state=0,stratify=wineY)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_credit = credit_trgX.shape[0]\n",
    "N_wine = wine_trgX.shape[0]\n",
    "\n",
    "alphas = [10**-x for x in np.arange(1,4.01,1/2)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Linear SVM ###\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    #warnings.filterwarnings(\"ignore\",category=DataConversionWarning)\n",
    "    #import md5, sha\n",
    "    \n",
    "    \n",
    "    pipeW = Pipeline([('Scale',StandardScaler()),\n",
    "    #                 ('Cull1',SelectFromModel(RandomForestClassifier(random_state=1),threshold='median')),\n",
    "    #                 ('Cull2',SelectFromModel(RandomForestClassifier(random_state=2),threshold='median')),\n",
    "    #                 ('Cull3',SelectFromModel(RandomForestClassifier(random_state=3),threshold='median')),\n",
    "    #                 ('Cull4',SelectFromModel(RandomForestClassifier(random_state=4),threshold='median')),\n",
    "                    ('SVM',SGDClassifier(loss='hinge',l1_ratio=0,penalty='l2',\n",
    "                                         class_weight='balanced',random_state=55))])\n",
    "    pipeC = Pipeline([('Scale',StandardScaler()),                \n",
    "                    ('SVM',SGDClassifier(loss='hinge',l1_ratio=0,penalty='l2',\n",
    "                                         class_weight='balanced',random_state=55))])\n",
    "\n",
    "    params_credit = {'SVM__alpha':alphas,'SVM__max_iter':[int((1e6/N_credit)/.8)+1]}\n",
    "    params_wine = {'SVM__alpha':alphas,'SVM__max_iter':[int((1e6/N_wine)/.8)+1]}\n",
    "\n",
    "    wine_clf = basicResults_wine(pipeW,wine_trgX,wine_trgY,wine_tstX,wine_tstY,params_wine,'SVM_Lin','wine')        \n",
    "    credit_clf = basicResults_credit(pipeC,credit_trgX,credit_trgY,credit_tstX,credit_tstY,params_credit,'SVM_Lin','credit')        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR SVM CONTINUED...\n",
    "\n",
    "# Get paramters\n",
    "wine_final_params = wine_clf.best_params_\n",
    "credit_final_params =credit_clf.best_params_\n",
    "\n",
    "print(wine_final_params)\n",
    "print(credit_final_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR SVM CONTINUED...\n",
    "\n",
    "# use final params to estimate OF params\n",
    "\n",
    "#wine_final_params = {'SVM__alpha': 0.01, 'SVM__max_iter': 110}\n",
    "wine_OF_params = {'SVM__max_iter': 275, 'SVM__alpha': 0.001}\n",
    "#credit_final_params ={'SVM__alpha': 0.0031622776601683794, 'SVM__max_iter': 60}\n",
    "credit_OF_params ={'SVM__max_iter': 179, 'SVM__alpha': 0.1}\n",
    "print(credit_OF_params, wine_OF_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing Curve - Wine\n",
    "pipeW.set_params(**wine_final_params)                     \n",
    "makeTimingCurve(wineX,wineY,pipeW,'SVM_Lin','wine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing Curve - Credit\n",
    "pipeC.set_params(**credit_final_params)\n",
    "makeTimingCurve(creditX,creditY,pipeC,'SVM_Lin','credit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve - Wine\n",
    "pipeW.set_params(**wine_final_params)\n",
    "iterationLC(pipeW,wine_trgX,wine_trgY,wine_tstX,wine_tstY,\n",
    "            {'SVM__max_iter':np.arange(1,500,50)},'SVM_Lin','wine')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve - Credit\n",
    "pipeC.set_params(**credit_final_params)\n",
    "iterationLC(pipeC,credit_trgX,credit_trgY,credit_tstX,credit_tstY,\n",
    "            {'SVM__max_iter':np.arange(1,300,50)},'SVM_Lin','credit')                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  wine\n",
    "pipeW.set_params(**wine_OF_params)\n",
    "iterationLC_wine(pipeW,wine_trgX,wine_trgY,wine_tstX,wine_tstY,\n",
    "            {'SVM__max_iter':np.arange(1,500,50)},'SVM_LinOF','wine')                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit\n",
    "pipeC.set_params(**credit_OF_params)\n",
    "iterationLC_credit(pipeC,credit_trgX,credit_trgY,credit_tstX,credit_tstY,\n",
    "            {'SVM__max_iter':np.arange(1,300,50)},'SVM_LinOF','credit')  \n",
    "\n",
    "\n",
    "### END LINEAR SVM ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN Radial Basis Function SVM  ###\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# wine has smaller sample size so each point is more important (larger gamma)   \n",
    "gamma_fracsW = np.arange(0.2,2.1,0.4)\n",
    "gamma_fracsC = np.arange(0.05,1.01,0.3)\n",
    "\n",
    "#\n",
    "pipeW = Pipeline([('Scale',StandardScaler()),\n",
    "                  # no need for feature selection\n",
    "#                  ('Cull1',SelectFromModel(RandomForestClassifier(random_state=1),threshold='median')),\n",
    "#                  ('Cull2',SelectFromModel(RandomForestClassifier(random_state=2),threshold='median')),\n",
    "#                  ('Cull3',SelectFromModel(RandomForestClassifier(random_state=3),threshold='median')),\n",
    "#                  ('Cull4',SelectFromModel(RandomForestClassifier(random_state=4),threshold='median')),\n",
    "                 ('SVM',primalSVM_RBF())])\n",
    "\n",
    "pipeC = Pipeline([('Scale',StandardScaler()),\n",
    "                 ('SVM',primalSVM_RBF())])\n",
    "\n",
    "\n",
    "params_credit = {'SVM__alpha':alphas,'SVM__max_iter':[int((1e6/N_credit)/.8)+1],'SVM__gamma_frac':gamma_fracsC}\n",
    "params_wine = {'SVM__alpha':alphas,'SVM__max_iter':[int((1e6/N_wine)/.8)+1],'SVM__gamma_frac':gamma_fracsW}\n",
    "#                                                  \n",
    "wine_clf = basicResults_wine(pipeW,wine_trgX,wine_trgY,wine_tstX,wine_tstY,params_wine,'SVM_RBF','wine')        \n",
    "credit_clf = basicResults_credit(pipeC,credit_trgX,credit_trgY,credit_tstX,credit_tstY,params_credit,'SVM_RBF','credit')        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get params - wine\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "# get params - credit \n",
    "credit_final_params =credit_clf.best_params_\n",
    "\n",
    "print(wine_final_params)\n",
    "print(credit_final_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_OF_params = wine_final_params.copy()\n",
    "# select best alpha from wine_final_params\n",
    "wine_OF_params['SVM__alpha'] = 0.001 #0.00031622776601683794\n",
    "\n",
    "credit_OF_params = credit_final_params.copy()\n",
    "# select best alpha from wine_final_params\n",
    "credit_OF_params['SVM__alpha'] = 0.01    #0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing Curve _ wine\n",
    "pipeW.set_params(**wine_final_params)                     \n",
    "makeTimingCurve(wineX,wineY,pipeW,'SVM_RBF','wine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing Curve - credit\n",
    "pipeC.set_params(**credit_final_params)\n",
    "makeTimingCurve(creditX,creditY,pipeC,'SVM_RBF','credit')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve - wine\n",
    "pipeW.set_params(**wine_final_params)\n",
    "iterationLC_wine(pipeW,wine_trgX,wine_trgY,wine_tstX,wine_tstY,\n",
    "                 {'SVM__max_iter':np.arange(1,500,50)},'SVM_RBF','wine')        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve - Credit\n",
    "pipeC.set_params(**credit_final_params)\n",
    "iterationLC_credit(pipeC,credit_trgX,credit_trgY,credit_tstX,credit_tstY,\n",
    "                   {'SVM__max_iter':np.arange(1,301,50)},'SVM_RBF','credit')                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine\n",
    "pipeW.set_params(**wine_OF_params)\n",
    "iterationLC_wine(pipeW,wine_trgX,wine_trgY,wine_tstX,wine_tstY,\n",
    "                 {'SVM__max_iter':np.arange(1,501,50)},'SVM_RBF_OF','wine')                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit\n",
    "pipeC.set_params(**credit_OF_params)\n",
    "iterationLC_credit(pipeC,credit_trgX,credit_trgY,credit_tstX,credit_tstY,\n",
    "                   {'SVM__max_iter':np.arange(1,301,50)},'SVM_RBF_OF','credit')     \n",
    "\n",
    "### END RBF SVM ####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
