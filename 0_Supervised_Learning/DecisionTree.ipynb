{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Edited to fit needs of my data & analysis\n",
    "Jamie Andrews\n",
    "Feb 3 2019\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Originally created on Fri Jan 20 13:55:38 2017\n",
    "@author: JTay\n",
    "source = https://github.com/JonathanTay/CS-7641-assignment-1\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from time import clock\n",
    "import sklearn.model_selection as ms\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn.tree import DecisionTreeClassifier as dtclf\n",
    "\n",
    "\n",
    "def balanced_accuracy(truth,pred):\n",
    "    wts = compute_sample_weight('balanced',truth)\n",
    "    return accuracy_score(truth,pred,sample_weight=wts)\n",
    "\n",
    "scorer = make_scorer(balanced_accuracy)    \n",
    "    \n",
    "def basicResults_wine(clfObj,trgX,trgY,tstX,tstY,params,clf_type=None,dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    # cv set to 3 for wine data to insure n is suffciently large with each cross cut\n",
    "    cv = ms.GridSearchCV(clfObj,n_jobs=1,param_grid=params,refit=True,verbose=10,cv=3,scoring=scorer)\n",
    "    cv.fit(trgX,trgY)\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    regTable.to_csv('./output/{}_{}_reg.csv'.format(clf_type,dataset),index=False)\n",
    "    test_score = cv.score(tstX,tstY)\n",
    "    with open('./output/test results.csv','a') as f:\n",
    "        f.write('{},{},{},{}\\n'.format(clf_type,dataset,test_score,cv.best_params_))    \n",
    "    N = trgY.shape[0]    \n",
    "    curve = ms.learning_curve(cv.best_estimator_,trgX,trgY,cv=3,\n",
    "                              train_sizes=[100,250]+[int(N*x/10) for x in range(1,7)],verbose=10,scoring=scorer)\n",
    "    curve_train_scores = pd.DataFrame(index = curve[0],data = curve[1])\n",
    "    curve_test_scores  = pd.DataFrame(index = curve[0],data = curve[2])\n",
    "    curve_train_scores.to_csv('./output/{}_{}_LC_train.csv'.format(clf_type,dataset))\n",
    "    curve_test_scores.to_csv('./output/{}_{}_LC_test.csv'.format(clf_type,dataset))\n",
    "    return cv\n",
    "\n",
    "def basicResults_credit(clfObj,trgX,trgY,tstX,tstY,params,clf_type=None,dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    # cv =5 for credit data bc there is more data to sample from\n",
    "    cv = ms.GridSearchCV(clfObj,n_jobs=1,param_grid=params,refit=True,verbose=10,cv=5,scoring=scorer)\n",
    "    cv.fit(trgX,trgY)\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    regTable.to_csv('./output/{}_{}_reg.csv'.format(clf_type,dataset),index=False)\n",
    "    test_score = cv.score(tstX,tstY)\n",
    "    with open('./output/test results.csv','a') as f:\n",
    "        f.write('{},{},{},{}\\n'.format(clf_type,dataset,test_score,cv.best_params_))    \n",
    "    N = trgY.shape[0]    \n",
    "    curve = ms.learning_curve(cv.best_estimator_,trgX,trgY,cv=5,\n",
    "                              train_sizes=[250,500,1000]+[int(N*x/10) for x in range(1,7)],verbose=10,scoring=scorer)\n",
    "    curve_train_scores = pd.DataFrame(index = curve[0],data = curve[1])\n",
    "    curve_test_scores  = pd.DataFrame(index = curve[0],data = curve[2])\n",
    "    curve_train_scores.to_csv('./output/{}_{}_LC_train.csv'.format(clf_type,dataset))\n",
    "    curve_test_scores.to_csv('./output/{}_{}_LC_test.csv'.format(clf_type,dataset))\n",
    "    return cv\n",
    "    \n",
    "def iterationLC_wine(clfObj,trgX,trgY,tstX,tstY,params,clf_type=None,dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    cv = ms.GridSearchCV(clfObj,n_jobs=1,param_grid=params,refit=True,verbose=10,cv=3,scoring=scorer)\n",
    "    cv.fit(trgX,trgY)\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    regTable.to_csv('./output/ITER_base_{}_{}.csv'.format(clf_type,dataset),index=False)\n",
    "    d = defaultdict(list)\n",
    "    name = list(params.keys())[0]\n",
    "    for value in list(params.values())[0]:        \n",
    "        d['param_{}'.format(name)].append(value)\n",
    "        clfObj.set_params(**{name:value})\n",
    "        clfObj.fit(trgX,trgY)\n",
    "        pred = clfObj.predict(trgX)\n",
    "        d['train acc'].append(balanced_accuracy(trgY,pred))\n",
    "        clfObj.fit(trgX,trgY)\n",
    "        pred = clfObj.predict(tstX)\n",
    "        d['test acc'].append(balanced_accuracy(tstY,pred))\n",
    "        print(value)\n",
    "    d = pd.DataFrame(d)\n",
    "    d.to_csv('./output/ITERtestSET_{}_{}.csv'.format(clf_type,dataset),index=False)\n",
    "    return cv    \n",
    "\n",
    "def iterationLC_credit(clfObj,trgX,trgY,tstX,tstY,params,clf_type=None,dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    cv = ms.GridSearchCV(clfObj,n_jobs=1,param_grid=params,refit=True,verbose=10,cv=5,scoring=scorer)\n",
    "    cv.fit(trgX,trgY)\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    regTable.to_csv('./output/ITER_base_{}_{}.csv'.format(clf_type,dataset),index=False)\n",
    "    d = defaultdict(list)\n",
    "    name = list(params.keys())[0]\n",
    "    for value in list(params.values())[0]:        \n",
    "        d['param_{}'.format(name)].append(value)\n",
    "        clfObj.set_params(**{name:value})\n",
    "        clfObj.fit(trgX,trgY)\n",
    "        pred = clfObj.predict(trgX)\n",
    "        d['train acc'].append(balanced_accuracy(trgY,pred))\n",
    "        clfObj.fit(trgX,trgY)\n",
    "        pred = clfObj.predict(tstX)\n",
    "        d['test acc'].append(balanced_accuracy(tstY,pred))\n",
    "        print(value)\n",
    "    d = pd.DataFrame(d)\n",
    "    d.to_csv('./output/ITERtestSET_{}_{}.csv'.format(clf_type,dataset),index=False)\n",
    "    return cv    \n",
    "    \n",
    "def add_noise(y,frac=0.1):\n",
    "    np.random.seed(456)\n",
    "    n = y.shape[0]\n",
    "    sz = int(n*frac)\n",
    "    ind = np.random.choice(np.arange(n),size=sz,replace=False)\n",
    "    tmp = y.copy()\n",
    "    tmp[ind] = 1-tmp[ind]\n",
    "    return tmp\n",
    "    \n",
    "    \n",
    "def makeTimingCurve(X,Y,clf,clfName,dataset):\n",
    "    out = defaultdict(dict)\n",
    "    for frac in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:    \n",
    "        X_train, X_test, y_train, y_test = ms.train_test_split(X, Y, test_size=frac, random_state=42)\n",
    "        st = clock()\n",
    "        np.random.seed(55)\n",
    "        clf.fit(X_train,y_train)\n",
    "        out['train'][frac]= clock()-st\n",
    "        st = clock()\n",
    "        clf.predict(X_test)\n",
    "        out['test'][frac]= clock()-st\n",
    "        print(clfName,dataset,frac)\n",
    "    out = pd.DataFrame(out)\n",
    "    out.to_csv('./output/{}_{}_timing.csv'.format(clfName,dataset))\n",
    "    return \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "class dtclf_pruned(dtclf):        \n",
    "    def remove_subtree(self,root):\n",
    "        '''Clean up'''\n",
    "        tree = self.tree_\n",
    "        visited,stack= set(),[root]\n",
    "        while stack:\n",
    "            v = stack.pop()\n",
    "            visited.add(v)\n",
    "            left =tree.children_left[v]\n",
    "            right=tree.children_right[v]\n",
    "            if left >=0:\n",
    "                stack.append(left)\n",
    "            if right >=0:\n",
    "                stack.append(right)\n",
    "        for node in visited:\n",
    "            tree.children_left[node] = -1\n",
    "            tree.children_right[node] = -1\n",
    "        return \n",
    "        \n",
    "    def prune(self):      \n",
    "        C = 1-self.alpha\n",
    "        if self.alpha <= -1: # Early exit\n",
    "            return self\n",
    "        tree = self.tree_        \n",
    "        bestScore = self.score(self.valX,self.valY)        \n",
    "        candidates = np.flatnonzero(tree.children_left>=0)\n",
    "        for candidate in reversed(candidates): # Go backwards/leaves up\n",
    "            if tree.children_left[candidate]==tree.children_right[candidate]: # leaf node. Ignore\n",
    "                continue\n",
    "            left = tree.children_left[candidate]\n",
    "            right = tree.children_right[candidate]\n",
    "            tree.children_left[candidate]=tree.children_right[candidate]=-1            \n",
    "            score = self.score(self.valX,self.valY)\n",
    "            if score >= C*bestScore:\n",
    "                bestScore = score                \n",
    "                self.remove_subtree(candidate)\n",
    "            else:\n",
    "                tree.children_left[candidate]=left\n",
    "                tree.children_right[candidate]=right\n",
    "        assert (self.tree_.children_left>=0).sum() == (self.tree_.children_right>=0).sum() \n",
    "        return self\n",
    "        \n",
    "    def fit(self,X,Y,sample_weight=None,check_input=True, X_idx_sorted=None):        \n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones(X.shape[0]) \n",
    "        self.trgX = X.copy()\n",
    "        self.trgY = Y.copy()\n",
    "        self.trgWts = sample_weight.copy()        \n",
    "        sss = ms.StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=123)\n",
    "        for train_index, test_index in sss.split(self.trgX,self.trgY):\n",
    "            self.valX = self.trgX[test_index]\n",
    "            self.valY = self.trgY[test_index]\n",
    "            self.trgX = self.trgX[train_index]\n",
    "            self.trgY = self.trgY[train_index]\n",
    "            self.valWts = sample_weight[test_index]\n",
    "            self.trgWts = sample_weight[train_index]\n",
    "        super().fit(self.trgX,self.trgY,self.trgWts,check_input,X_idx_sorted)\n",
    "        self.prune()\n",
    "        return self\n",
    "    def __init__(self,\n",
    "                 criterion=\"gini\",\n",
    "                 splitter=\"best\",\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.,\n",
    "                 max_features=None,\n",
    "                 random_state=None,\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_decrease=1e-7,\n",
    "                 class_weight=None,\n",
    "                 presort=False,\n",
    "                 alpha = 0):\n",
    "        super(dtclf_pruned, self).__init__(\n",
    "            criterion=criterion,\n",
    "            splitter=splitter,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_features=max_features,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            class_weight=class_weight,\n",
    "            random_state=random_state,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            presort=presort)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def numNodes(self):\n",
    "        assert (self.tree_.children_left>=0).sum() == (self.tree_.children_right>=0).sum() \n",
    "        return  (self.tree_.children_left>=0).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GET THE DATA ============\n",
    "\n",
    "# wine data\n",
    "file_path =\"./data/\"\n",
    "wine = pd.read_csv (file_path+'wines.csv', sep =\",\")\n",
    "# credit data\n",
    "file_path2 =\"./data/\"\n",
    "credit = pd.read_csv (file_path2+'credit.csv', sep =\",\")\n",
    "\n",
    "# Break out predicting and target variable data    \n",
    "wineX = wine.drop('quality',1).copy().values\n",
    "wineY = wine['quality'].copy().values\n",
    "\n",
    "creditX = credit.drop('default',1).copy().values\n",
    "creditY = credit['default'].copy().values\n",
    "\n",
    "# DIVIDE INTO TRAIN AND TEST SETS  \n",
    "wine_trgX, wine_tstX, wine_trgY, wine_tstY = ms.train_test_split(\n",
    "    wineX, wineY, test_size=0.3, random_state=0,stratify=wineY)     \n",
    "\n",
    "credit_trgX, credit_tstX, credit_trgY, credit_tstY = ms.train_test_split(\n",
    "    creditX, creditY, test_size=0.3, random_state=0,stratify=creditY)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load DecisionTree.py\n",
    "\"\"\"\n",
    "Created on Wed Jan 18 11:55:32 2017\n",
    "Script for full tests, decision tree (pruned)\n",
    "\"\"\"\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "import pandas as pd\n",
    "#from helpers import basicResults,dtclf_pruned,makeTimingCurve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# def DTpruningVSnodes(clf,alphas,trgX,trgY,dataset):\n",
    "#     '''Dump table of pruning alpha vs. # of internal nodes'''\n",
    "#     out = {}\n",
    "#     for a in alphas:\n",
    "#         clf.set_params(**{'DT__alpha':a})\n",
    "#         clf.fit(trgX,trgY)\n",
    "#         out[a]=clf.steps[-1][-1].numNodes()\n",
    "#         score = clf.score(trgX,trgY) \n",
    "#         print(dataset,a, score)\n",
    "#     out = pd.Series(out)\n",
    "#     out.index.name='alpha'\n",
    "#     out.name = 'Number of Internal Nodes'\n",
    "#     out.to_csv('./output/DT_{}_nodecounts.csv'.format(dataset))\n",
    "    \n",
    "#     return\n",
    "\n",
    "def DTpruningVSnodes(clf,alphas,trgX,trgY,dataset):\n",
    "    '''Dump table of pruning alpha vs. # of internal nodes'''\n",
    "    out = {}\n",
    "    results = []\n",
    "    for a in alphas:\n",
    "        clf.set_params(**{'DT__alpha':a})\n",
    "        clf.fit(trgX,trgY)\n",
    "        nodes =clf.steps[-1][-1].numNodes()\n",
    "        score = clf.score(trgX,trgY)\n",
    "        out[a]=clf.steps[-1][-1].numNodes()\n",
    "        print(dataset,a, nodes, score)\n",
    "        res = (dataset,a, nodes, score)\n",
    "        results.append(res)\n",
    "    out2 = pd.DataFrame(results)\n",
    "    out = pd.Series(out)\n",
    "    out.index.name='alpha'\n",
    "    out.name = 'Number of Internal Nodes'\n",
    "    out.to_csv('./output/DT_{}_nodecounts.csv'.format(dataset))\n",
    "    out2.to_csv('./output/DT_{}_prune_acc.csv'.format(dataset))\n",
    "    return\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the data\n",
    "creditX.shape, creditY.shape, wineX.shape, wineY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Search for good alphas\n",
    "alphas = [-1,-1e-3,-(1e-3)*10**-0.5, -1e-2, \n",
    "          -(1e-2)*10**-0.5,-1e-1,-(1e-1)*10**-0.5, 0, \n",
    "          (1e-1)*10**-0.5,1e-1,(1e-2)*10**-0.5,1e-2,(1e-3)*10**-0.5,1e-3, 1]\n",
    "\n",
    "#alphas=[0]\n",
    "\n",
    "# define wine pipeline\n",
    "pipeW = Pipeline([('Scale',StandardScaler()),\n",
    "                  # feature selection migh be a good idea but we are not going to do it here\n",
    "#                  ('Cull1',SelectFromModel(RandomForestClassifier(random_state=1),threshold='median')),\n",
    "#                  ('Cull2',SelectFromModel(RandomForestClassifier(random_state=2),threshold='median')),\n",
    "#                  ('Cull3',SelectFromModel(RandomForestClassifier(random_state=3),threshold='median')),\n",
    "#                  ('Cull4',SelectFromModel(RandomForestClassifier(random_state=4),threshold='median')),\n",
    "                 ('DT',dtclf_pruned(random_state=55))])\n",
    "\n",
    "\n",
    "# define credit pipeline\n",
    "pipeC = Pipeline([('Scale',StandardScaler()),                 \n",
    "                 ('DT',dtclf_pruned(random_state=55))])\n",
    "\n",
    "# define params to use in gridsearch\n",
    "params = {'DT__criterion':['gini','entropy'],'DT__alpha':alphas,'DT__class_weight':['balanced']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate thru different params to find best params\n",
    "\n",
    "# iterate for wine params\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    wine_clf = basicResults_wine(pipeW,wine_trgX,wine_trgY,wine_tstX,wine_tstY,params,'DT','wine') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate for credit params\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")#,category=DeprecationWarning)\n",
    "    credit_clf = basicResults_credit(pipeC,credit_trgX,credit_trgY,credit_tstX,credit_tstY,params,'DT','credit')        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign best params/ look at the final params for both data sets\n",
    "\n",
    "#wine_final_params = {'DT__alpha': -0.00031622776601683794, 'DT__class_weight': 'balanced', 'DT__criterion': 'entropy'}\n",
    "#credit_final_params = {'class_weight': 'balanced', 'alpha': 0.0031622776601683794, 'criterion': 'entropy'}\n",
    "wine_final_params = wine_clf.best_params_\n",
    "credit_final_params = credit_clf.best_params_\n",
    "\n",
    "print(wine_final_params, credit_final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create timing curve for wine\n",
    "pipeW.set_params(**wine_final_params)\n",
    "makeTimingCurve(wineX,wineY,pipeW,'DT','wine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit timing curve for credit\n",
    "pipeC.set_params(**credit_final_params)\n",
    "makeTimingCurve(creditX,creditY,pipeC,'DT','credit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune wine\n",
    "DTpruningVSnodes(pipeW,alphas,wine_trgX,wine_trgY,'wine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune credit\n",
    "DTpruningVSnodes(pipeC,alphas,credit_trgX,credit_trgY,'credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
